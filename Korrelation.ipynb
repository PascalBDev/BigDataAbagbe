{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04c5f007",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "from pyspark import SparkConf, SparkContext\n",
    "import json\n",
    "import time\n",
    "import math \n",
    "import sys, math\n",
    "from pyspark.sql.functions import col\n",
    "import pandas as pd\n",
    "from pyspark.ml.stat import Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206a8868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WIRD NICHT BENÖTIGT\n",
    "#conf = SparkConf().setAppName(\"Korrelation\").setMaster(\"local[*]\").set(\"spark.executor.memory\", '10g').set(\"spark.driver.memory\",'10g')\n",
    "#conf = SparkConf().setAppName(\"Korrelation_new\").setMaster(\"spark://192.168.1.247:7077\")\n",
    "#sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8331207e",
   "metadata": {},
   "source": [
    "bei .master (\"local[*]\") einsetzen, oder ein master + slaves starten (steigert Performance um das 4-fache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f46dc0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = pyspark.sql.SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"Amazon Reviews\") \\\n",
    "    .getOrCreate()\n",
    "# .master(\"spark://192.168.1.247:7077\") \\\n",
    "\n",
    "# Lade JSON Datei\n",
    "df = spark.read.json(r'C:\\Users\\klass\\data\\Appliances.json')\n",
    "\n",
    "# Entferne Spalten\n",
    "df = df.drop('verified', 'reviewTime',\"reviewerID\", \"asin\",\"reviewerName\",\"summary\",\"unixReviewTime\",\"vote\", \"style\", \"image\")\n",
    "df = df.fillna(\" \", subset=[\"reviewText\"])\n",
    "df = df.withColumn(\"Textlänge_integer\", pyspark.sql.functions.length('reviewText'))\n",
    "df = df.withColumn(\"Textlänge\", col(\"Textlänge_integer\").cast(\"double\"))\n",
    "df = df.drop(\"reviewText\", \"Textlänge_integer\")\n",
    "df.fillna(0, subset=[\"Textlänge\"])\n",
    "\n",
    "# Dataframe in RDD konvertieren.\n",
    "partitionen = 10\n",
    "data = df.rdd.repartition(partitionen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92d5f82",
   "metadata": {},
   "source": [
    "# Korrelation step by step selber berechnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d329ab6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Korrelation:  -0.17476299418809313\n",
      "Execution time: 50.51594424247742\n"
     ]
    }
   ],
   "source": [
    "def calculate_mean(data, column):\n",
    "    return data.map(lambda x: x[column]).sum() / n\n",
    "\n",
    "def calculate_std(data, column, mean):\n",
    "    return math.sqrt(data.map(lambda x: (x[column] - mean)**2).sum() / n)\n",
    "\n",
    "def calculate_cov(data, column1, column2, mean1, mean2):\n",
    "    return data.map(lambda x: (x[column1] - mean1) * (x[column2] - mean2)).sum() / n\n",
    "\n",
    "start_time = time.time()\n",
    "n = data.count()\n",
    "mean_col1 = calculate_mean(data, 0)\n",
    "mean_col2 = calculate_mean(data, 1)\n",
    "std_col1 = calculate_std(data, 0, mean_col1)\n",
    "std_col2 = calculate_std(data, 1, mean_col2)\n",
    "covXY = calculate_cov(data, 0, 1, mean_col1, mean_col2)\n",
    "correlation = covXY / (std_col1 * std_col2)\n",
    "\n",
    "print(\"Korrelation: \", correlation)\n",
    "print(f\"Execution time: {time.time() - start_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7fccba",
   "metadata": {},
   "source": [
    "# Pyspark.SQL Korrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1351665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Korrelation:  -0.1747629941880985\n",
      "Execution time: 0.5975379943847656\n"
     ]
    }
   ],
   "source": [
    "#Korrelation berechnen\n",
    "start_time = time.time()\n",
    "correlation = pyspark.sql.DataFrameStatFunctions(df).corr(\"overall\", \"Textlänge\")\n",
    "print(\"Korrelation: \", correlation)\n",
    "print(f\"Execution time: {time.time() - start_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566f1d5e",
   "metadata": {},
   "source": [
    "# Pandas Korrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f26ac180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 2.397836446762085\n"
     ]
    }
   ],
   "source": [
    "#DataFrame in ein Pandas_Dataframe umwandeln\n",
    "start_time = time.time()\n",
    "data = df.toPandas()\n",
    "print(f\"Execution time: {time.time() - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f9c419a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            overall  Textlänge\n",
      "overall    1.000000  -0.174763\n",
      "Textlänge -0.174763   1.000000\n",
      "Execution time: 0.029915571212768555\n"
     ]
    }
   ],
   "source": [
    "#Korrelation mit Panda-DataFrame berechnen\n",
    "start_time = time.time()\n",
    "print(data.corr(numeric_only = True))\n",
    "print(f\"Execution time: {time.time() - start_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5f4490",
   "metadata": {},
   "source": [
    "# Code um Duplikate zu bilden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e740216b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.json(r'C:\\Users\\klass\\data\\all_beauty.json')\n",
    "\n",
    "# Inhalt duplizieren\n",
    "df = df.union(df)\n",
    "df = df.coalesce(1)\n",
    "\n",
    "# Inhalt in eine Datei schreiben\n",
    "df.write.json(\"duplicated_large_file.json\", mode=\"overwrite\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
